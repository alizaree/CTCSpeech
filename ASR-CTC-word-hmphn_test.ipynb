{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "from hdf5storage import loadmat, savemat\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from api.preprocessing import sound2coch\n",
    "from api.librispeech import LibriDataset\n",
    "from api.model import SpeechRecognitionCTC\n",
    "\n",
    "# CUDA for PyTorch\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency dimension: 65, alphabet size: 10002\n"
     ]
    }
   ],
   "source": [
    "LibriDataset.set_mode('word') # Should be one of 'grapheme', 'phoneme', 'word'\n",
    "\n",
    "freq_bins = 65\n",
    "size_vocab = LibriDataset.vocab_size()\n",
    "print(f'Frequency dimension: {freq_bins}, alphabet size: {size_vocab}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word-5-500\n"
     ]
    }
   ],
   "source": [
    "N_LAYER, N_NODES = 5, 500\n",
    "model_id = f'{LibriDataset.MODE}-{N_LAYER}-{N_NODES}'\n",
    "model_arch = dict(rnn_hidden_size=N_NODES, nb_layers=N_LAYER, window_size=1, rnn_stride=1)\n",
    "model_name = 'models/model-ctc-{:s}'.format(model_id)\n",
    "\n",
    "print(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpeechRecognitionCTC(rnn_type=nn.GRU, labels=LibriDataset.alphabet(), **model_arch, freq_bins=freq_bins)\n",
    "model = model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(f'{model_name}.pt', map_location=device))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "(443, 500)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "alphabet = LibriDataset.alphabet()\n",
    "maindir='./sounds/homophones/'\n",
    "nTrial=37\n",
    "activation=[]\n",
    "prediction=[]\n",
    "\n",
    "actv=[]\n",
    "pred=[]\n",
    "#make a list of names\n",
    "root_dir = os.getcwd()\n",
    "os.chdir(maindir+'soundTemp/')\n",
    "sounds_names = glob.glob('*.wav')\n",
    "os.chdir(root_dir)\n",
    "sounds_names=[nm[0:-4] for nm in sounds_names]\n",
    "print( len(sounds_names))\n",
    "\n",
    "for nm in sounds_names: \n",
    "    sound_file = maindir+'soundTemp/'+nm+'.wav'\n",
    "    cochleagram = sound2coch(sound_file)\n",
    "    prediction.append(model.get_prediction(cochleagram))\n",
    "    activation.append(model.get_activation(cochleagram))\n",
    "\n",
    "    \n",
    "print((activation[0][0].shape)) # dimentions: trial, layer,time,neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hmphn_1f1_trl2', 'hmphn_0m3_trl5', 'hmphn_0m2_trl5', 'hmphn_1m3_trl17', 'hmphn_2m2_trl13', 'hmphn_1m1_trl6', 'hmphn_0f3_trl1', 'hmphn_0f2_trl1', 'hmphn_2f1_trl13', 'hmphn_2m1_trl8', 'hmphn_2m1_trl9', 'hmphn_1m1_trl7', 'hmphn_3f3_trl17', 'hmphn_1m3_trl16', 'hmphn_0f2_trl13', 'hmphn_0m2_trl4', 'hmphn_0m3_trl4', 'hmphn_1f1_trl3', 'hmphn_0m1_trl13', 'hmphn_1f1_trl1', 'hmphn_0m1_trl11', 'hmphn_0f1_trl19', 'hmphn_0f2_trl11', 'hmphn_0m2_trl19', 'hmphn_3m3_trl8', 'hmphn_1m3_trl14', 'hmphn_3m2_trl8', 'hmphn_3f3_trl15', 'hmphn_2m2_trl10', 'hmphn_0f2_trl2', 'hmphn_0f3_trl2', 'hmphn_2f1_trl10', 'hmphn_0f3_trl3', 'hmphn_0f2_trl3', 'hmphn_3m3_trl20', 'hmphn_1m1_trl4', 'hmphn_3m2_trl9', 'hmphn_1m3_trl15', 'hmphn_3m3_trl9', 'hmphn_0m2_trl18', 'hmphn_0f2_trl10', 'hmphn_0m3_trl7', 'hmphn_0m2_trl7', 'hmphn_0f1_trl18', 'hmphn_0m1_trl10', 'hmphn_1f1_trl4', 'hmphn_0m1_trl14', 'hmphn_0f1_trl20', 'hmphn_0m2_trl3', 'hmphn_0m3_trl3', 'hmphn_1f3_trl19', 'hmphn_1m3_trl11', 'hmphn_0m2_trl20', 'hmphn_0f2_trl14', 'hmphn_2m2_trl15', 'hmphn_0f2_trl7', 'hmphn_0f3_trl7', 'hmphn_3f3_trl9', 'hmphn_3f2_trl9', 'hmphn_2f1_trl15', 'hmphn_3f2_trl8', 'hmphn_3f3_trl8', 'hmphn_3m3_trl19', 'hmphn_1m1_trl1', 'hmphn_0f2_trl15', 'hmphn_0m3_trl2', 'hmphn_0m2_trl2', 'hmphn_0m1_trl15', 'hmphn_0m1_trl17', 'hmphn_1f1_trl7', 'hmphn_1m3_trl12', 'hmphn_0f2_trl17', 'hmphn_2f1_trl9', 'hmphn_2m2_trl16', 'hmphn_1m1_trl3', 'hmphn_3f3_trl13', 'hmphn_0f3_trl4', 'hmphn_0f2_trl4', 'hmphn_2f1_trl16', 'hmphn_2f1_trl17', 'hmphn_0f2_trl5', 'hmphn_0f3_trl5', 'hmphn_3f3_trl12', 'hmphn_1m1_trl2', 'hmphn_2m2_trl17', 'hmphn_2f1_trl8', 'hmphn_0f2_trl16', 'hmphn_1m3_trl13', 'hmphn_0m2_trl1', 'hmphn_0m3_trl1', 'hmphn_1f1_trl6', 'hmphn_0m1_trl16', 'hmphn_2m3_trl13', 'hmphn_0m1_trl9', 'hmphn_3m1_trl7', 'hmphn_1f1_trl17', 'hmphn_1m2_trl17', 'hmphn_2m3_trl4', 'hmphn_2m2_trl4', 'hmphn_3f1_trl3', 'hmphn_3f1_trl2', 'hmphn_2m2_trl5', 'hmphn_0f3_trl13', 'hmphn_2m3_trl5', 'hmphn_1m2_trl16', 'hmphn_1f1_trl16', 'hmphn_3m1_trl6', 'hmphn_2f2_trl1', 'hmphn_2f3_trl1', 'hmphn_3m1_trl17', 'hmphn_3f2_trl17', 'hmphn_0m1_trl8', 'hmphn_2m3_trl10', 'hmphn_3f2_trl15', 'hmphn_3m1_trl15', 'hmphn_2f2_trl3', 'hmphn_2f3_trl3', 'hmphn_3m1_trl4', 'hmphn_1f1_trl14', 'hmphn_1m3_trl9', 'hmphn_1m2_trl9', 'hmphn_1m2_trl14', 'hmphn_0m3_trl19', 'hmphn_0f3_trl11', 'hmphn_3f1_trl1', 'hmphn_0f3_trl10', 'hmphn_0m3_trl18', 'hmphn_1m2_trl15', 'hmphn_1m2_trl8', 'hmphn_1m3_trl8', 'hmphn_1f1_trl15', 'hmphn_3m1_trl5', 'hmphn_2f3_trl2', 'hmphn_3f1_trl20', 'hmphn_2f2_trl2', 'hmphn_3m2_trl20', 'hmphn_2m3_trl15', 'hmphn_1f3_trl8', 'hmphn_1f2_trl8', 'hmphn_3m1_trl1', 'hmphn_1f1_trl11', 'hmphn_1m1_trl19', 'hmphn_2m2_trl2', 'hmphn_2m3_trl2', 'hmphn_0f3_trl14', 'hmphn_1m2_trl11', 'hmphn_1f2_trl19', 'hmphn_0m3_trl20', 'hmphn_3f1_trl5', 'hmphn_3f1_trl4', 'hmphn_0f3_trl15', 'hmphn_2m3_trl3', 'hmphn_2m2_trl3', 'hmphn_3f1_trl19', 'hmphn_1f2_trl9', 'hmphn_1f3_trl9', 'hmphn_3m2_trl19', 'hmphn_3f2_trl13', 'hmphn_2m3_trl16', 'hmphn_2f3_trl5', 'hmphn_2f2_trl5', 'hmphn_3m1_trl13', 'hmphn_3m1_trl2', 'hmphn_0f1_trl8', 'hmphn_1f1_trl12', 'hmphn_2m3_trl1', 'hmphn_0f3_trl17', 'hmphn_2m2_trl1', 'hmphn_1m2_trl12', 'hmphn_3f1_trl6', 'hmphn_3f1_trl7', 'hmphn_1m2_trl13', 'hmphn_0f3_trl16', 'hmphn_1f1_trl13', 'hmphn_0f1_trl9', 'hmphn_3m1_trl3', 'hmphn_3m1_trl12', 'hmphn_2f2_trl4', 'hmphn_2f3_trl4', 'hmphn_2m3_trl17', 'hmphn_3f2_trl12', 'hmphn_3m2_trl17', 'hmphn_1f3_trl7', 'hmphn_1f2_trl7', 'hmphn_2f2_trl9', 'hmphn_2f3_trl9', 'hmphn_3f1_trl17', 'hmphn_1m1_trl16', 'hmphn_0f1_trl4', 'hmphn_1m3_trl3', 'hmphn_1m2_trl3', 'hmphn_0m3_trl13', 'hmphn_1f2_trl16', 'hmphn_1f2_trl17', 'hmphn_1m2_trl2', 'hmphn_1m3_trl2', 'hmphn_0f1_trl5', 'hmphn_1m1_trl17', 'hmphn_2f3_trl8', 'hmphn_2f2_trl8', 'hmphn_1f2_trl6', 'hmphn_1f3_trl6', 'hmphn_2f3_trl13', 'hmphn_0m1_trl1', 'hmphn_0m1_trl3', 'hmphn_3f2_trl20', 'hmphn_1f2_trl4', 'hmphn_1f3_trl4', 'hmphn_3m1_trl20', 'hmphn_0f1_trl7', 'hmphn_1m1_trl15', 'hmphn_0f3_trl18', 'hmphn_0m3_trl10', 'hmphn_1f2_trl15', 'hmphn_3f1_trl9', 'hmphn_3f1_trl8', 'hmphn_1f2_trl14', 'hmphn_0m3_trl11', 'hmphn_0f3_trl19', 'hmphn_1m3_trl1', 'hmphn_1m2_trl1', 'hmphn_1m1_trl14', 'hmphn_3f1_trl15', 'hmphn_2f3_trl10', 'hmphn_3m2_trl15', 'hmphn_0m1_trl2', 'hmphn_3f2_trl19', 'hmphn_1f2_trl1', 'hmphn_1f3_trl1', 'hmphn_3m1_trl19', 'hmphn_3m1_trl8', 'hmphn_0f1_trl2', 'hmphn_0m3_trl15', 'hmphn_0m3_trl14', 'hmphn_1m2_trl19', 'hmphn_1f2_trl11', 'hmphn_0f3_trl20', 'hmphn_1m3_trl4', 'hmphn_1m2_trl4', 'hmphn_1f1_trl19', 'hmphn_1m1_trl11', 'hmphn_0f1_trl3', 'hmphn_3m1_trl9', 'hmphn_0m1_trl7', 'hmphn_2f3_trl15', 'hmphn_2f3_trl17', 'hmphn_3m2_trl12', 'hmphn_0m1_trl5', 'hmphn_1f3_trl2', 'hmphn_1f2_trl2', 'hmphn_3f1_trl12', 'hmphn_1m1_trl13', 'hmphn_0f1_trl1', 'hmphn_1m3_trl6', 'hmphn_1m2_trl6', 'hmphn_1f2_trl13', 'hmphn_2m2_trl8', 'hmphn_2m3_trl8', 'hmphn_0m3_trl16', 'hmphn_0m3_trl17', 'hmphn_2m3_trl9', 'hmphn_2m2_trl9', 'hmphn_1f2_trl12', 'hmphn_1m2_trl7', 'hmphn_1m3_trl7', 'hmphn_1m1_trl12', 'hmphn_3f1_trl13', 'hmphn_1f2_trl3', 'hmphn_1f3_trl3', 'hmphn_0m1_trl4', 'hmphn_3m2_trl13', 'hmphn_2f3_trl16', 'hmphn_0f1_trl13', 'hmphn_3m3_trl2', 'hmphn_1f3_trl16', 'hmphn_3m2_trl2', 'hmphn_0m2_trl13', 'hmphn_2f1_trl5', 'hmphn_3m3_trl17', 'hmphn_0f2_trl8', 'hmphn_0f3_trl8', 'hmphn_3f3_trl6', 'hmphn_3f2_trl6', 'hmphn_2m1_trl1', 'hmphn_2m1_trl13', 'hmphn_3f2_trl7', 'hmphn_3f3_trl7', 'hmphn_0f3_trl9', 'hmphn_0f2_trl9', 'hmphn_2f2_trl13', 'hmphn_2f1_trl4', 'hmphn_3m2_trl3', 'hmphn_1f3_trl17', 'hmphn_3m3_trl3', 'hmphn_0f1_trl10', 'hmphn_0m1_trl18', 'hmphn_1f1_trl8', 'hmphn_3m2_trl1', 'hmphn_3m3_trl1', 'hmphn_1f3_trl15', 'hmphn_0m2_trl10', 'hmphn_0f2_trl18', 'hmphn_3f3_trl20', 'hmphn_3f2_trl5', 'hmphn_3f3_trl5', 'hmphn_2m1_trl2', 'hmphn_2m1_trl3', 'hmphn_2m1_trl10', 'hmphn_3f3_trl4', 'hmphn_3f2_trl4', 'hmphn_3m3_trl15', 'hmphn_2f2_trl10', 'hmphn_0f2_trl19', 'hmphn_0m2_trl11', 'hmphn_1f3_trl14', 'hmphn_1f1_trl9', 'hmphn_0m1_trl19', 'hmphn_0f1_trl11', 'hmphn_0f1_trl15', 'hmphn_0m2_trl15', 'hmphn_3m2_trl4', 'hmphn_3m3_trl4', 'hmphn_2f1_trl3', 'hmphn_3f3_trl19', 'hmphn_1m1_trl9', 'hmphn_3f3_trl1', 'hmphn_3f2_trl1', 'hmphn_2m1_trl15', 'hmphn_1m1_trl8', 'hmphn_2f2_trl15', 'hmphn_2f1_trl2', 'hmphn_1f3_trl11', 'hmphn_1m3_trl19', 'hmphn_3m3_trl5', 'hmphn_3m2_trl5', 'hmphn_0f2_trl20', 'hmphn_0m2_trl14', 'hmphn_0f1_trl14', 'hmphn_0m1_trl20', 'hmphn_0f1_trl16', 'hmphn_0m2_trl9', 'hmphn_0m3_trl9', 'hmphn_0m2_trl16', 'hmphn_3m3_trl7', 'hmphn_1f3_trl13', 'hmphn_3m2_trl7', 'hmphn_3m3_trl12', 'hmphn_2f2_trl17', 'hmphn_2m1_trl17', 'hmphn_3f3_trl3', 'hmphn_3f2_trl3', 'hmphn_2m1_trl4', 'hmphn_2m1_trl5', 'hmphn_3f2_trl2', 'hmphn_3f3_trl2', 'hmphn_2m1_trl16', 'hmphn_2f2_trl16', 'hmphn_3m3_trl13', 'hmphn_2f1_trl1', 'hmphn_3m2_trl6', 'hmphn_1f3_trl12', 'hmphn_3m3_trl6', 'hmphn_0m2_trl17', 'hmphn_0m3_trl8', 'hmphn_0m2_trl8', 'hmphn_0f1_trl17']\n"
     ]
    }
   ],
   "source": [
    "print(sounds_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HE WOULD QUIT HELP HIS FUTURE WAS <NIL> BELIEVE HE WOULD DO IT ANY THAN MOST PLAYS\n"
     ]
    }
   ],
   "source": [
    "print(prediction[23])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom inferrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_hmpn_and_trl(word):\n",
    "    a=word.split('_')\n",
    "    hmphn=a[1][:-2]\n",
    "    trl=a[2][3:]\n",
    "    return int(hmphn),int(trl)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import give_hmphn_trl_label\n",
    "Data,Labels,OpLabels=give_hmphn_trl_label(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEAR PAIR\n",
      "PEAR PAIR\n",
      "PEAR PAIR\n",
      "PEAR PAIR\n",
      "FLOUR FLOWER\n",
      "PAIR PEAR\n",
      "PAIR PEAR\n",
      "PEAR PAIR\n",
      "FLOUR FLOWER\n",
      "PEAR PAIR\n",
      "FLOUR FLOWER\n",
      "FLOWER FLOUR\n",
      "FLOWER FLOUR\n",
      "PEAR PAIR\n",
      "FLOWER FLOUR\n",
      "PAIR PEAR\n",
      "FLOWER FLOUR\n",
      "PEAR PAIR\n",
      "PAIR PEAR\n",
      "PEAR PAIR\n",
      "FLOWER FLOUR\n",
      "FLOWER FLOUR\n",
      "FLOUR FLOWER\n",
      "FLOUR FLOWER\n",
      "FLOWER FLOUR\n",
      "PEAR PAIR\n",
      "PEAR PAIR\n",
      "PAIR PEAR\n",
      "PAIR PEAR\n",
      "FLOWER FLOUR\n",
      "FLOWER FLOUR\n",
      "PEAR PAIR\n",
      "PAIR PEAR\n",
      "PEAR PAIR\n",
      "FLOUR FLOWER\n",
      "PEAR PAIR\n",
      "PEAR PAIR\n",
      "FLOWER FLOUR\n",
      "FLOUR FLOWER\n",
      "PAIR PEAR\n",
      "PAIR PEAR\n",
      "FLOUR FLOWER\n",
      "FLOUR FLOWER\n",
      "FLOUR FLOWER\n",
      "FLOWER FLOUR\n",
      "FLOWER FLOUR\n",
      "FLOUR FLOWER\n",
      "PEAR PAIR\n",
      "PAIR PEAR\n",
      "PAIR PEAR\n",
      "PEAR PAIR\n",
      "FLOUR FLOWER\n",
      "PAIR PEAR\n",
      "PEAR PAIR\n",
      "PEAR PAIR\n",
      "PAIR PEAR\n",
      "FLOUR FLOWER\n",
      "FLOWER FLOUR\n",
      "FLOWER FLOUR\n",
      "PEAR PAIR\n",
      "PEAR PAIR\n",
      "FLOUR FLOWER\n",
      "PEAR PAIR\n",
      "PAIR PEAR\n",
      "PEAR PAIR\n",
      "PAIR PEAR\n",
      "FLOUR FLOWER\n",
      "FLOUR FLOWER\n",
      "FLOWER FLOUR\n",
      "PAIR PEAR\n",
      "PAIR PEAR\n",
      "FLOWER FLOUR\n",
      "FLOWER FLOUR\n",
      "FLOWER FLOUR\n",
      "FLOUR FLOWER\n",
      "PAIR PEAR\n",
      "PAIR PEAR\n",
      "FLOUR FLOWER\n",
      "FLOUR FLOWER\n",
      "PAIR PEAR\n",
      "PAIR PEAR\n",
      "FLOWER FLOUR\n",
      "FLOWER FLOUR\n",
      "FLOWER FLOUR\n",
      "FLOUR FLOWER\n",
      "PEAR PAIR\n",
      "PEAR PAIR\n",
      "FLOUR FLOWER\n",
      "PAIR PEAR\n",
      "PAIR PEAR\n",
      "PAIR PEAR\n",
      "PAIR PEAR\n",
      "PEAR PAIR\n",
      "PEAR PAIR\n",
      "PEAR PAIR\n",
      "PEAR PAIR\n",
      "PEAR PAIR\n",
      "PEAR PAIR\n",
      "FLOWER FLOUR\n",
      "PEAR PAIR\n",
      "PEAR PAIR\n",
      "FLOWER FLOUR\n",
      "PAIR PEAR\n",
      "PAIR PEAR\n",
      "FLOWER FLOUR\n",
      "FLOUR FLOWER\n",
      "PEAR PAIR\n",
      "PEAR PAIR\n",
      "PEAR PAIR\n",
      "PEAR PAIR\n",
      "FLOWER FLOUR\n",
      "FLOWER FLOUR\n",
      "FLOWER FLOUR\n",
      "PEAR PAIR\n",
      "PEAR PAIR\n",
      "FLOWER FLOUR\n",
      "FLOUR FLOWER\n",
      "PAIR PEAR\n",
      "PEAR PAIR\n",
      "PEAR PAIR\n",
      "PEAR PAIR\n",
      "PAIR PEAR\n",
      "PEAR PAIR\n",
      "FLOWER FLOUR\n",
      "FLOWER FLOUR\n",
      "PEAR PAIR\n",
      "PEAR PAIR\n",
      "FLOWER FLOUR\n",
      "PAIR PEAR\n",
      "PEAR PAIR\n",
      "PEAR PAIR\n",
      "PAIR PEAR\n",
      "PAIR PEAR\n",
      "PEAR PAIR\n",
      "PEAR PAIR\n",
      "PAIR PEAR\n",
      "FLOWER FLOUR\n",
      "PAIR PEAR\n",
      "PAIR PEAR\n",
      "FLOWER FLOUR\n",
      "FLOUR FLOWER\n",
      "PAIR PEAR\n",
      "FLOUR FLOWER\n",
      "FLOUR FLOWER\n",
      "FLOUR FLOWER\n",
      "FLOUR FLOWER\n",
      "FLOUR FLOWER\n",
      "FLOUR FLOWER\n",
      "FLOWER FLOUR\n",
      "PEAR PAIR\n",
      "FLOWER FLOUR\n",
      "PEAR PAIR\n",
      "FLOUR FLOWER\n",
      "FLOUR FLOWER\n",
      "PAIR PEAR\n",
      "FLOWER FLOUR\n",
      "FLOUR FLOWER\n",
      "FLOUR FLOWER\n",
      "FLOUR FLOWER\n",
      "FLOUR FLOWER\n",
      "FLOWER FLOUR\n",
      "PEAR PAIR\n",
      "PAIR PEAR\n",
      "FLOUR FLOWER\n",
      "FLOUR FLOWER\n",
      "FLOWER FLOUR\n",
      "PAIR PEAR\n",
      "FLOUR FLOWER\n",
      "FLOUR FLOWER\n",
      "PEAR PAIR\n",
      "PEAR PAIR\n",
      "PAIR PEAR\n",
      "FLOUR FLOWER\n",
      "FLOUR FLOWER\n",
      "FLOUR FLOWER\n",
      "PAIR PEAR\n",
      "FLOUR FLOWER\n",
      "FLOWER FLOUR\n",
      "FLOWER FLOUR\n",
      "FLOWER FLOUR\n",
      "FLOUR FLOWER\n",
      "FLOUR FLOWER\n",
      "FLOWER FLOUR\n",
      "FLOUR FLOWER\n",
      "PAIR PEAR\n",
      "FLOUR FLOWER\n"
     ]
    }
   ],
   "source": [
    "total_count=0\n",
    "corr_count=0\n",
    "for ad, nm in enumerate(sounds_names):\n",
    "    hmphn,trl=give_hmpn_and_trl(nm)\n",
    "    label=Labels[hmphn][trl].upper()\n",
    "    oplabel=OpLabels[hmphn][trl].upper()\n",
    "    if label in alphabet and oplabel in alphabet:\n",
    "        print(label, oplabel)\n",
    "        if label in prediction[ad] or oplabel in prediction[ad]:\n",
    "            total_count+=1\n",
    "            if label in prediction[ad]:\n",
    "                corr_count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 98 the ratio of choosing correctly: 0.6836734693877551 the ratio of missing the sound 0.2677595628415301\n"
     ]
    }
   ],
   "source": [
    "print(corr_count,total_count,'the ratio of choosing correctly:', corr_count/total_count,\n",
    "      'the ratio of missing the sound', total_count/(len(sounds_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print('my'.upper() in alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
