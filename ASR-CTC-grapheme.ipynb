{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HViixfxp8mVX"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1233,
     "status": "error",
     "timestamp": 1595009046060,
     "user": {
      "displayName": "Ali Zare",
      "photoUrl": "",
      "userId": "12832949783293874649"
     },
     "user_tz": 240
    },
    "id": "jVRvCsWo8mVZ",
    "outputId": "36ca009d-188b-4543-9897-18fd84ec0a10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "from hdf5storage import loadmat, savemat\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from api.preprocessing import sound2coch\n",
    "from api.librispeech import LibriDataset\n",
    "from api.model import SpeechRecognitionCTC\n",
    "\n",
    "# CUDA for PyTorch\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Et1pxdcs8mVd"
   },
   "source": [
    "## Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hSIPmpDR8mVd",
    "outputId": "aca6e253-2217-4e9b-af7b-c4662fdd1d7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency dimension: 65, alphabet size: 31\n"
     ]
    }
   ],
   "source": [
    "LibriDataset.set_mode('grapheme') # Should be one of 'grapheme', 'phoneme', 'word'\n",
    "\n",
    "freq_bins = 65\n",
    "size_vocab = LibriDataset.vocab_size()\n",
    "print(f'Frequency dimension: {freq_bins}, alphabet size: {size_vocab}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zm6xPRsy8mVg",
    "outputId": "754269bd-3a20-4a7c-9abe-4d3d35e8b3f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grapheme-5-500\n"
     ]
    }
   ],
   "source": [
    "N_LAYER, N_NODES = 5, 500\n",
    "model_id = f'{LibriDataset.MODE}-{N_LAYER}-{N_NODES}'\n",
    "model_arch = dict(rnn_hidden_size=N_NODES, nb_layers=N_LAYER, window_size=10, rnn_stride=2)\n",
    "model_name = 'models/model-ctc-{:s}'.format(model_id)\n",
    "\n",
    "print(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CIw8Hayu8mVi"
   },
   "outputs": [],
   "source": [
    "model = SpeechRecognitionCTC(rnn_type=nn.GRU, labels=LibriDataset.alphabet(), **model_arch, freq_bins=freq_bins)\n",
    "model = model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(f'{model_name}.pt', map_location=device))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ckBaTFJt8mVo"
   },
   "source": [
    "## Inferrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e6_xPWIz8mVo",
    "outputId": "e45575f3-3061-491e-f4c4-ae694b2ab8f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "H O W <SPACE> T O <SPACE> I D E N T I F I <SPACE> A <SPACE> B I R D <SPACE> H A V E <SPACE> Y O U <SPACE> H A V E <SPACE> H E R S E E N <SPACE> A <SPACE> B I R D <SPACE> A T <SPACE> Y O U R <SPACE> F E E T E R <SPACE> T H A T <SPACE> Y O U <SPACE> R E A L L Y <SPACE> L I K E <SPACE> B U T <SPACE> J U S T <SPACE> C A N N O T <SPACE> S E E M <SPACE> T O <SPACE> F I G U R E <SPACE> O U T <SPACE> W H A T <SPACE> I T <SPACE> I S <SPACE> Y O U <SPACE> S H O U L D <SPACE> L E A R N <SPACE> H O <SPACE> T O <SPACE> I D E N T I F Y <SPACE> A <SPACE> B I R D <SPACE> A N D <SPACE> I <SPACE> W I L L <SPACE> E X P L A I N <SPACE> H O W <SPACE> T O <SPACE> D O <SPACE> S O <SPACE> F I R S T <SPACE> Y O U <SPACE> N E E <SPACE> T O <SPACE> C A T A G A R E Z E <SPACE> T H E <SPACE> B I R D <SPACE> T H E R E <SPACE> A R E <SPACE> E I T <SPACE> D I F F E R E N T <SPACE> C A B T A G O R I E S <SPACE> T H A T <SPACE> T H E Y K I N <SPACE> G O I N G <SPACE> T O <SPACE> A S <SPACE> S O O N <SPACE> A S <SPACE> Y O U <SPACE> S E E <SPACE> T H E <SPACE> B I R D <SPACE> Y O U <SPACE> S H O U L D <SPACE> T R Y <SPACE> T O <SPACE> P U T <SPACE> I T <SPACE> I N T O <SPACE> O N E <SPACE> O F <SPACE> T H E S E <SPACE> C A T A G O R I S <SPACE> D O C K S <SPACE> A N D <SPACE> D U C K L I K E <SPACE> B I R D S <SPACE> G O S <SPACE> A N D <SPACE> T U R N S <SPACE> L O N G <SPACE> L I G G A D <SPACE> W A T E R S <SPACE> S H O R E <SPACE> B I R D S <SPACE> A N D <SPACE> S M A L L <SPACE> W A T E R S <SPACE> F O L L <SPACE> L I K E <SPACE> B I R D S <SPACE> B U R D S <SPACE> O F <SPACE> P R A Y <SPACE> F L Y <SPACE> C A T C H E R S <SPACE> W A R B L E R S <SPACE> Y O U <SPACE> S H O U L D <SPACE> P A Y <SPACE> T E N T I O N <SPACE> T O <SPACE> H O W <SPACE> B I G <SPACE> O R <SPACE> S M A L L <SPACE> T H E <SPACE> B I R D E S <SPACE> Y O U <SPACE> C A N <SPACE> U S E <SPACE> S I Z E <SPACE> R E L A T I V I T Y <SPACE> T O <SPACE> G E T <SPACE> A <SPACE> G E N E R A L <SPACE> I D E A <SPACE> S I Z S E <SPACE> R E L A T I V I T Y <SPACE> R E F E R S <SPACE> T O <SPACE> B E I N G <SPACE> B I G G E R <SPACE> O R <SPACE> S M A L L E R <SPACE> T H E N <SPACE> A <SPACE> S P A R O <SPACE> R O B I N <SPACE> C R O W <SPACE> O R <SPACE> P I G O N <SPACE> P E R C E L <SPACE> S T U D Y <SPACE> S Y L L O E T S <SPACE> B E <SPACE> S I L L O E T <SPACE> I S <SPACE> A N <SPACE> I M P O R T A N T <SPACE> P A R T <SPACE> O F <SPACE> Y <SPACE> D E N T I F Y I N G <SPACE> I T <SPACE> W H E N <SPACE> I T <SPACE> I S <SPACE> F L Y I N G <SPACE> A N <SPACE> Y O U <SPACE> C A N N O T <SPACE> S E E <SPACE> A L L <SPACE> T H E <SPACE> D E T A I L S <SPACE> J U S T <SPACE> P A T E N T I O N <SPACE> T O <SPACE> I T S <SPACE> B O D Y <SPACE> B E K <SPACE> T L <SPACE> A N D <SPACE> L E G S <SPACE> A S K <SPACE> Y O U R S E L F <SPACE> T H E S E <SPACE> Q U E S T I O N S <SPACE> I S <SPACE> T H E <SPACE> B O D Y <SPACE> S H O R T <SPACE> O R <SPACE> L O N G <SPACE> N A R R O W <SPACE> O R <SPACE> P L U M P <SPACE> I S <SPACE> I T S <SPACE> B E K <SPACE> F I N E <SPACE> L O N G <SPACE> O R <SPACE> S H O R T A N <SPACE> S T O T <SPACE> I S <SPACE> I T <SPACE> D A G G R S A P E D <SPACE> H O O K D <SPACE> O R <SPACE> S T R A I G H T <SPACE> I S <SPACE> T H E <SPACE> B I R D S <SPACE> T A I L <SPACE> R O U N D E D <SPACE> S Q U A R E <SPACE> P O I N T E D <SPACE> O R <SPACE> F O R K T <SPACE> O R E <SPACE> I T S <SPACE> L E G S <SPACE> S H O R T <SPACE> O R <SPACE> L O N G <SPACE> D O <SPACE> T H E <SPACE> W I N G S <SPACE> L O O K <SPACE> R O U N D E D <SPACE> O R <SPACE> P O I N T E D <SPACE> D I D <SPACE> T H E <SPACE> W I N G S <SPACE> H A V E <SPACE> W I N G <SPACE> B A R S <SPACE> I F <SPACE> S O <SPACE> A R E <SPACE> T H E Y <SPACE> S I N G L E <SPACE> O R <SPACE> D O U B L E <SPACE> B O W D <SPACE> O R <SPACE> A B S C U R E <SPACE> P A Y I T <SPACE> E N T I O N <SPACE> T O <SPACE> T H E <SPACE> B I R D S <SPACE> B E H A V I O R <SPACE> D I F F E R E N T <SPACE> B I R D S <SPACE> S H A V E <SPACE> D I F F E N T <SPACE> B E H A V I O R S <SPACE> F O R <SPACE> E X A M P L E <SPACE> W H E N <SPACE> W O U L D <SPACE> P A C K E R S <SPACE> C L A M <SPACE> O F <SPACE> A T R E E <SPACE> O N E <SPACE> M I G H T <SPACE> C L I M B <SPACE> I N <SPACE> S P I R A L E S <SPACE> A N D <SPACE> T H E <SPACE> O T H E R <SPACE> M Y <SPACE> C L I M B I N <SPACE> J E R K S <SPACE> A L S O <SPACE> T H E Y <SPACE> M I G H T <SPACE> C L I M <SPACE> U S I N G <SPACE> T H E I R <SPACE> T A I L <SPACE> A S <SPACE> A <SPACE> B R A C E <SPACE> O R <SPACE> H A D <SPACE> F I R S T <SPACE> I F <SPACE> Y O U <SPACE> K N O W <SPACE> H I T <SPACE> A <SPACE> B U R D S <SPACE> B E H A V E I Y O U R <SPACE> I S <SPACE> L I K E <SPACE> T H I S <SPACE> C O N <SPACE> B E <SPACE> A <SPACE> H E L P F U L <SPACE> T O O L <SPACE> I N D <SPACE> I <SPACE> D E N T <SPACE> I F I I N G <SPACE> T A K E <SPACE> N O T E <SPACE> O N W A R E <SPACE> Y O U <SPACE> S A W <SPACE> T H E <SPACE> B I R D <SPACE> T H E R E <SPACE> M Y G H T <SPACE> B E <SPACE> A <SPACE> B E R D <SPACE> T H A T <SPACE> L O O K E S <SPACE> E X A C T L Y <SPACE> L I K E <SPACE> I T <SPACE> B U T <SPACE> H I S <SPACE> O N <SPACE> T H E <SPACE> W H O L E <SPACE> O T H E R <SPACE> S I D E <SPACE> O F <SPACE> T H E <SPACE> W O R L D <SPACE> R A N G E <SPACE> A S <SPACE> A <SPACE> V E R Y <SPACE> I M P O R T A N T <SPACE> P A R T <SPACE> I N D <SPACE> I <SPACE> D E N T I F Y I N G <SPACE> B I R D S <SPACE> D O <SPACE> N O T <SPACE> D E P E N D <SPACE> O N <SPACE> C O L O U R <SPACE> B U R D S <SPACE> M A Y <SPACE> H A V E <SPACE> A <SPACE> D I F F E R E N T <SPACE> P L U M A G E <SPACE> I T <SPACE> T D I F F E R E N T <SPACE> T I M E S <SPACE> O F <SPACE> T H E <SPACE> Y E A R <SPACE> S O <SPACE> T H E <SPACE> C O L O R <SPACE> O F <SPACE> T H E I R <SPACE> F A T H E R S <SPACE> M I G H T <SPACE> N O T <SPACE> T E L L <SPACE> Y O U <SPACE> W H A T <SPACE> K I N D I T I S <SPACE> Y O U <SPACE> S H O U L D <SPACE> U S E <SPACE> C O L O R <SPACE> A S <SPACE> A L A S T <SPACE> W A S O R T <SPACE> I T <SPACE> I S <SPACE> B E S T <SPACE> T O <SPACE> A L S O <SPACE> U S E <SPACE> I F <SPACE> F E E L D <SPACE> G U I D <SPACE> B E C A U S E <SPACE> Y O U <SPACE> W I L L <SPACE> H A V E <SPACE> A L L <SPACE> T H E <SPACE> I N F O M A T I O N <SPACE> R E C O R D E D <SPACE> W H E N <SPACE> Y O U <SPACE> G O <SPACE> T O <SPACE> L O O K <SPACE> A T <SPACE> O U P <SPACE> P A I N T E D <SPACE> P I C T U R E S <SPACE> I N <SPACE> F E E L D <SPACE> G U I D E S <SPACE> A R E <SPACE> O F T E N <SPACE> B E T T E R <SPACE> T H A N <SPACE> F O T O S <SPACE> B E C A U S E <SPACE> F H O T O G R A P H S <SPACE> S O M E T I M E S <SPACE> H A V E <SPACE> L I G T I N G <SPACE> P R O P L E M S <SPACE> M O S T <SPACE> F E E L D <SPACE> G U I D E S <SPACE> H A V E <SPACE> C A T T E G O R I S <SPACE> T H A T <SPACE> T H E <SPACE> B I R D S <SPACE> A R E <SPACE> P U T <SPACE> I N T O <SPACE> O R <SPACE> T H E Y <SPACE> S E P A R A T E <SPACE> T H E M <SPACE> B Y <SPACE> F A M I L Y <SPACE> Y O U <SPACE> C A N <SPACE> P E R C H A S E <SPACE> F E E L D <SPACE> G U I D E S <SPACE> I N <SPACE> E X P E N S I V E L Y <SPACE> O R <SPACE> L O O K <SPACE> A T <SPACE> O N E <SPACE> F R O M <SPACE> Y O U R <SPACE> L O C A L <SPACE> L I B R A R Y <SPACE> F O T O G R A P H I N G <SPACE> T H E <SPACE> B I R D <SPACE> A F T E R <SPACE> Y O U\n"
     ]
    }
   ],
   "source": [
    "alphabet = LibriDataset.alphabet()\n",
    "sound_file = './unattended_story_2.wav'\n",
    "cochleagram = sound2coch(sound_file)\n",
    "\n",
    "pred = model.get_prediction(cochleagram)\n",
    "actv = model.get_activation(cochleagram)\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ERoq3OpN8mVr",
    "outputId": "a8ec4ac7-529f-4157-ef64-67d686e28af2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8923, 500)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actv[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5WJHrQvl8mVu"
   },
   "source": [
    "## Custom inferrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ntlBjBGb8mVu"
   },
   "outputs": [],
   "source": [
    "# trans = []\n",
    "# for layer in range(nb_layers):\n",
    "#     svd = sklearn.decomposition.TruncatedSVD(n_components=65, n_iter=25)\n",
    "#     svd.fit(acts_libri[layer])\n",
    "#     trans.append(svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y7Mc26vm8mVw",
    "outputId": "29b81467-d110-4629-c1fe-16a23777b7dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alizare/opt/anaconda3/envs/envTF113/lib/python3.7/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/archive/menoua/Data/LibriSpeech/LibriSpeech/train-clean-100/1098/133695/1098-133695-0005.flac'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/envTF113/lib/python3.7/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/envTF113/lib/python3.7/site-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    626\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 627\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/envTF113/lib/python3.7/site-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1181\u001b[0m         _error_check(_snd.sf_error(file_ptr),\n\u001b[0;32m-> 1182\u001b[0;31m                      \"Error opening {0!r}: \".format(self.name))\n\u001b[0m\u001b[1;32m   1183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/envTF113/lib/python3.7/site-packages/soundfile.py\u001b[0m in \u001b[0;36m_error_check\u001b[0;34m(err, prefix)\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_error_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1355\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error opening '/archive/menoua/Data/LibriSpeech/LibriSpeech/train-clean-100/1098/133695/1098-133695-0005.flac': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6049e6fd3caf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0malphabet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLibriDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphabet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msound_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/archive/menoua/Data/LibriSpeech/LibriSpeech/train-clean-100/1098/133695/1098-133695-0005.flac'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcochleagram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msound2coch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msound_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/CTCSpeech/Ali/api/preprocessing.py\u001b[0m in \u001b[0;36msound2coch\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;34m\"\"\"Convert sound file to cochleagram\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcgram_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'downsample'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/envTF113/lib/python3.7/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PySoundFile failed. Trying audioread instead.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/envTF113/lib/python3.7/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/envTF113/lib/python3.7/site-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/envTF113/lib/python3.7/site-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/archive/menoua/Data/LibriSpeech/LibriSpeech/train-clean-100/1098/133695/1098-133695-0005.flac'"
     ]
    }
   ],
   "source": [
    "alphabet = LibriDataset.alphabet()\n",
    "sound_file = '/archive/menoua/Data/LibriSpeech/LibriSpeech/train-clean-100/1098/133695/1098-133695-0005.flac'\n",
    "cochleagram = sound2coch(sound_file)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    xs = torch.Tensor(cochleagram).unsqueeze(0)\n",
    "    xs = xs.type(torch.float32).to(device)\n",
    "    xlen = torch.LongTensor([xs.shape[1]])\n",
    "    z, zlen = model.predict(xs, xlen)\n",
    "    \n",
    "    zi = [_ for _ in z.squeeze().argmax(dim=1)]\n",
    "    for i in range(len(zi)-1,0,-1):\n",
    "        if zi[i] == zi[i-1]: zi = zi[:i-1] + zi[i:]\n",
    "    zi = [alphabet[_] for _ in zi if _ > 0]\n",
    "    \n",
    "    zi = [' ' if _ == LibriDataset.SYM_SPACE else _ for _ in zi]\n",
    "    zi = ''.join(zi)\n",
    "    \n",
    "    print(zi)\n",
    "    print()\n",
    "    \n",
    "    activation = model.activations(xs)\n",
    "    activation = [x.squeeze(0).numpy().astype('float32') for x in activation]\n",
    "    # activation = [trans[layer].transform(activation[layer]) for layer in range(nb_layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oV9bK8ra8mVz",
    "outputId": "42d56ec6-291b-4955-fe07-4a050da1d019"
   },
   "outputs": [],
   "source": [
    "print(' '.join([str(x.shape) for x in activation]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X1bZ1obt8mV1"
   },
   "outputs": [],
   "source": [
    "# savemat(f'activations-ctc-{model_id}-100hz-20ms.mat', mdict={'acts_neural': acts_neural, 'stim_neural': stim_neural})"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ASR-CTC-grapheme.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
